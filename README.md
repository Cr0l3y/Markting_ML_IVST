Texto traduzido no translate.google EN. - Texto em PT-BR 

Text translated on translate.google EN. - Text in PT-BR 



***EN***

# Project


Project: Analysis of Marketing Investment Data

    üìå Objective

This project aims to analyze data related to marketing investments and understand patterns that can help in future strategic decisions.


    üîç Initial Data Analysis

Null Values: After the initial verification, it was found that there are no null values ‚Äã‚Äãin the dataset, therefore, there is no need to treat this aspect.

Data Consistency:

-Some categorical columns present values ‚Äã‚Äãthat can harm the analysis, such as categories written in different ways (e.g.: "Male", "male", "M").

-There is also no guarantee that the numerical variables are within an acceptable range. For example, the variable "age" could contain negative or absurdly high values, which needs to be verified.

-The column "adherence_investment" is of the categorical type, which indicates that the problem is a classification problem and not a regression problem.


    üìä Exploratory Data Analysis (EDA)

Visualization with Graphs (Plotly)

The exploratory analysis was conducted using interactive graphs with Plotly, starting with the target variable investment_adherence:

- Two categories were identified: "yes" (502 records) and "no" (766 records), with no signs of inconsistency.


Analysis of Categorical Variables

- For variables such as marital_status, education, default, loan_taken, we used colored bar graphs based on the category (color='investment_adherence') to verify the integrity of the information.

- Although it is a repetitive analysis, it is essential to ensure that there are no outliers or typing problems.

Analysis of Numerical Variables

Using boxplots, we identified:

- Age: ranges from 19 to 87 years old, with no negative values ‚Äã‚Äãor values ‚Äã‚Äãabove 200 years old.

- Balance: has negative values, which is acceptable, since it indicates possible debts.

Even with possible outliers, the data was kept, since it carries relevant information.

Exploratory analysis is a crucial step in Machine Learning projects, since it allows a better understanding of the data and detecting possible inconsistencies before modeling.


    üßπ Data Preparation

Separating Target Variable

        x = dados.drop("investment_adherence", axis=1)
        y = dados["investment_adherence"]

Treatment of Categorical Variables

- Many columns are in text format, which needs to be converted, since machine learning algorithms do not understand texts, only numbers.

- Although it is possible to transform the texts into simple numbers (e.g.: 1 = married, 2 = single), this would create a false hierarchy between the categories, which can negatively affect the model.

Solution: One-Hot Encoding

The One-Hot Encoding technique was used to transform categorical columns into numeric columns, without assigning false orders to the categories.

Each category is transformed into a new binary column:

1 indicates the presence of the feature.

0 indicates the absence.




---
***PT-BR***

# Projeto

Projeto: An√°lise de Dados de Investimentos em Marketing

    üìå Objetivo

Este projeto tem como objetivo analisar dados relacionados a investimentos em marketing e entender padr√µes que possam auxiliar em futuras decis√µes estrat√©gicas.


    üîç An√°lise Inicial dos Dados

Valores Nulos: Ap√≥s a verifica√ß√£o inicial, foi constatado que n√£o existem valores nulos no dataset, portanto, n√£o h√° necessidade de tratamento nesse aspecto.

Consist√™ncia dos Dados:

-Algumas colunas categ√≥ricas apresentam valores que podem prejudicar a an√°lise, como categorias escritas de formas diferentes (ex: "Masculino", "masculino", "M").

-Tamb√©m n√£o h√° garantias de que as vari√°veis num√©ricas estejam dentro de uma faixa aceit√°vel. Por exemplo, a vari√°vel "idade" poderia conter valores negativos ou absurdamente altos, o que precisa ser verificado.

-A coluna "aderencia_investimento" √© do tipo categ√≥rico, o que indica que o problema se trata de classifica√ß√£o e n√£o de regress√£o.


    üìä An√°lise Explorat√≥ria dos Dados (EDA)


Visualiza√ß√£o com Gr√°ficos (Plotly)


A an√°lise explorat√≥ria foi conduzida utilizando gr√°ficos interativos com Plotly, come√ßando pela vari√°vel alvo aderencia_investimento:

- Duas categorias foram identificadas: "sim" (502 registros) e "nao" (766 registros), sem ind√≠cios de inconsist√™ncia.

An√°lise das Vari√°veis Categ√≥ricas

- Para as vari√°veis como estado_civil, escolaridade, inadimplencia, fez_emprestimo, utilizamos gr√°ficos de barras coloridos com base na categoria (color='aderencia_investimento') para verificar a integridade das informa√ß√µes.

- Apesar de ser uma an√°lise repetitiva, ela √© essencial para garantir que n√£o h√° valores discrepantes ou problemas de digita√ß√£o.


An√°lise das Vari√°veis Num√©ricas

Com o uso de boxplots, identificamos:

- Idade: varia de 19 a 87 anos, sem valores negativos ou acima de 200 anos.

- Saldo: possui valores negativos, o que √© aceit√°vel, j√° que indica poss√≠veis d√≠vidas.


Mesmo com poss√≠veis outliers, os dados foram mantidos, pois carregam informa√ß√µes relevantes.

A an√°lise explorat√≥ria √© uma etapa crucial em projetos de Machine Learning, pois permite entender melhor os dados e detectar poss√≠veis inconsist√™ncias antes da modelagem.




    üßπ Prepara√ß√£o dos Dados

Separando Vari√°vel Alvo

        x = dados.drop("aderencia_investimento", axis=1)
        y = dados["aderencia_investimento"]


Tratamento das Vari√°veis Categ√≥ricas

- Muitas colunas est√£o em formato textual, o que precisa ser convertido, j√° que algoritmos de machine learning n√£o compreendem textos, apenas n√∫meros.

- Embora seja poss√≠vel transformar os textos em n√∫meros simples (ex: 1 = casado, 2 = solteiro), isso criaria uma falsa hierarquia entre as categorias, o que pode afetar negativamente o modelo.



Solu√ß√£o: One-Hot Encoding

- Utilizamos o One-Hot Encoder para transformar as colunas categ√≥ricas em colunas bin√°rias.

- Observa√ß√£o: Para colunas com apenas duas categorias como inadimplencia e fez_emprestimo, usamos o par√¢metro drop='if_binary' no OneHotEncoder, para evitar a cria√ß√£o de colunas redundantes (ex: apenas uma coluna onde 1 = sim e 0 = nao).


        from sklearn.preprocessing import OneHotEncoder

        encoder = OneHotEncoder(drop='if_binary')
        x_encoded = encoder.fit_transform(x)
        colunas = encoder.get_feature_names_out()


- Armazenamos os nomes das colunas transformadas em uma vari√°vel (colunas) para manter controle sobre as novas vari√°veis geradas.

- O encoder guarda o padr√£o dos dados, o que permite aplic√°-lo a futuros dados de forma consistente.



Transforma√ß√£o da Vari√°vel Alvo

- A vari√°vel aderencia_investimento tamb√©m precisa ser transformada, pois est√° em formato "sim"/"nao".

- Utilizamos o LabelEncoder do Scikit-Learn:


        from sklearn.preprocessing import LabelEncoder
        label_encoder = LabelEncoder()
        y = label_encoder.fit_transform(y)
     Resultado: 1 = sim, 0 = nao


ü§ñ Modelagem e Avalia√ß√£o


Divis√£o dos Dados:
- Para avaliar o desempenho do modelo, n√£o utilizamos todos os dados de uma vez.
- Dividimos em dados de treino e dados de teste com train_test_split:

        from sklearn.model_selection import train_test_split
        x_treino, x_teste, y_treino, y_teste = train_test_split(x_encoded, y, test_size=0.3, random_state=42)


Modelo 1: DummyClassifier
- O DummyClassifier serve como uma baseline para avaliarmos o desempenho m√≠nimo aceit√°vel:


        from sklearn.dummy import DummyClassifier
        dummy = DummyClassifier(strategy='most_frequent')
        dummy.fit(x_treino, y_treino)
        score_dummy = dummy.score(x_teste, y_teste)
    Resultado: 60,2% de acerto



Modelo 2: √Årvore de Decis√£o


- O modelo de √°rvore de decis√£o compara os valores das colunas para tomar decis√µes de classifica√ß√£o.


        from sklearn.tree import DecisionTreeClassifier

        modelo_arvore = DecisionTreeClassifier()
        modelo_arvore.fit(x_treino, y_treino)
        score_arvore = modelo_arvore.score(x_teste, y_teste)
    Resultado: 100% nos dados de treino

O modelo decorou os dados, o que causa overfitting.
- Aplicando Limite de Profundidade:



        modelo_podado = DecisionTreeClassifier(max_depth=3)
        modelo_podado.fit(x_treino, y_treino)
        score_podado = modelo_podado.score(x_teste, y_teste)
    Resultado: 71,6% de acerto

Com a poda da √°rvore (limite de profundidade), o modelo generalizou melhor, evitando o overfitting.

